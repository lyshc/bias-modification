{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias modification data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define functions for data extraction / analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for creating a dataframe based on each information in  PANAS/DOT/VS JSON files \n",
    "\n",
    "def file_info_to_dataframe(file_info_list, task_title):\n",
    "\n",
    "    # create the dataframe\n",
    "    file_df = pd.DataFrame(file_info_list, columns = ['ppt_id', task_title + '_file_name', 'time_info', 'file_type'])\n",
    "\n",
    "    # add 'time_cleaned' column, listing when task was performed \n",
    "    file_df['time_cleaned'] = pd.to_datetime(file_df['time_info'].astype(int)/1000, unit='s')\n",
    "\n",
    "    # sort dataframe by file_name (and so time)\n",
    "    file_df = file_df.sort_values([task_title + '_file_name'], ascending=[True]) \n",
    "    file_df.reset_index(drop=True, inplace = True) # reset index after sorting\n",
    "\n",
    "    # add 'rolling_count_ppt' column listing the rolling count of task files for each ppt, ordered by time\n",
    "    file_df['rolling_count_ppt'] = file_df.groupby(by='ppt_id').cumcount()+1\n",
    "\n",
    "    # create 'time_date' collumn; lists date when the task was performed (without hour/minute/second info)\n",
    "    file_df['time_date'] = file_df['time_cleaned'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "    return file_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for finding type of DOT or VS files (test, trial, active-training, sham-training)\n",
    "\n",
    "def get_game_info(game_files, game_file_info):\n",
    "    for i in game_files:\n",
    "        with open(i) as json_file:\n",
    "            game_json_data = json.load(json_file)\n",
    "            game_ppt_id = game_json_data['bbuid']\n",
    "            game_time_file = str(game_json_data['time'])\n",
    "            \n",
    "            if (game_json_data['data']['data'][0]['g_d']['t'] == 'test') and (game_json_data['data']['data'][0]['g_d']['f'] == 'ftue'):\n",
    "                game_file_info.append([game_ppt_id,i,game_time_file,'trial'])\n",
    "\n",
    "            elif (game_json_data['data']['data'][0]['g_d']['t'] == 'test') and (game_json_data['data']['data'][0]['g_d']['f'] == 'normal'):\n",
    "                game_file_info.append([game_ppt_id,i,game_time_file,'test'])\n",
    "\n",
    "            elif (game_json_data['data']['data'][0]['g_d']['t'] == 'training') and (game_json_data['data']['data'][0]['g_d']['v'] == 'Active'):\n",
    "                game_file_info.append([game_ppt_id,i,game_time_file,'active-training'])\n",
    "\n",
    "            elif (game_json_data['data']['data'][0]['g_d']['t'] == 'training') and (game_json_data['data']['data'][0]['g_d']['v'] == 'Sham'):\n",
    "                game_file_info.append([game_ppt_id,i,game_time_file,'sham-training'])\n",
    "\n",
    "            else:\n",
    "                game_file_info.append([game_ppt_id,i,game_time_file,'other'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for creating a dataframe with ppt ids and the training type conducted, for DOT or VS\n",
    "\n",
    "def split_game_ids_by_training_type_in_dfs(game_file_df_cleaned, game_active_training_df, game_sham_training_df):\n",
    "    # get unique ids of all ppts with any task file in a dataframe\n",
    "    game_ids_training_type_df = pd.DataFrame(game_file_df_cleaned.ppt_id.unique())\n",
    "\n",
    "    # rename first column as 'ppt_id'\n",
    "    game_ids_training_type_df.rename(columns={0: \"ppt_id\"}, inplace=True)\n",
    "\n",
    "    # identify ppts with active or sham training for this task\n",
    "    game_train_conditions = [\n",
    "        game_ids_training_type_df.ppt_id.isin(game_active_training_df.ppt_id),\n",
    "        game_ids_training_type_df.ppt_id.isin(game_sham_training_df.ppt_id)\n",
    "    ]\n",
    "\n",
    "    # specify training type choices for the training conditions\n",
    "    game_train_choices = ['active-training', 'sham-training']\n",
    "\n",
    "    # add training_type column, matching to game training conditions and choices; those without these are listed as no-training\n",
    "    game_ids_training_type_df['training_type'] = np.select(game_train_conditions, game_train_choices, default='no-training')\n",
    "\n",
    "    return game_ids_training_type_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function used when analysing accuracy of DOT and VS test files\n",
    "\n",
    "def is_correct(s):\n",
    "    return 1 if s == 'true' else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for adding DOT and VS training types to any mood dataframe\n",
    "\n",
    "def add_game_training_type_to_mood_dfs(mood_values_df, game_training_type_df, game_title):\n",
    "    \n",
    "    # merge data frm game_training_type_df to the moood df by ppt_id\n",
    "    split_mood_values_df = pd.merge(mood_values_df, game_training_type_df, how='left', on='ppt_id')\n",
    "    \n",
    "    # replace NaNs with 'no-task-info'; the ppts don't have relevant task files\n",
    "    split_mood_values_df = split_mood_values_df.fillna('no-' + game_title + '-info')\n",
    "    \n",
    "    # set name of training type column to match game_title\n",
    "    training_column_name = game_title + '_training_type'\n",
    "    split_mood_values_df.rename(columns={'training_type': training_column_name}, inplace=True)\n",
    "\n",
    "    return split_mood_values_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for setting overall training category of participants, based on DOT and VS data\n",
    "\n",
    "def mood_overall_training_category(mood_responses_by_training_df):\n",
    "\n",
    "    # identify ppts with as DOT-active, DOT-sham, VS-active, VS-sham, no-training\n",
    "    overall_train_conditions = [\n",
    "        (mood_responses_by_training_df['dot_training_type'] == \"active-training\"),\n",
    "        (mood_responses_by_training_df['dot_training_type'] == \"sham-training\"),\n",
    "        (mood_responses_by_training_df['vs_training_type'] == \"active-training\"),\n",
    "        (mood_responses_by_training_df['vs_training_type'] == \"sham-training\")\n",
    "    ]\n",
    "\n",
    "    # specify training type choices for the training conditions\n",
    "    overall_train_choices = ['dot-active-training', 'dot-sham-training', 'vs-active-training', 'vs-sham-training']\n",
    "\n",
    "    # add training_type column, matching to game training conditions and choices; those without these are listed as no-training\n",
    "    mood_responses_by_training_df['overall_training_type'] = np.select(overall_train_conditions, overall_train_choices, default='no-training')\n",
    "\n",
    "    return mood_responses_by_training_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sort into mood, dot and vs files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of files in current directory, ignoring hidden files\n",
    "all_files = sorted([f for f in os.listdir('./') if not f.startswith('.')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create lists to store file names in\n",
    "vs_files = []\n",
    "dot_files = []\n",
    "mood_files = []\n",
    "other_files = []\n",
    "file_info = [] # create df with cols: file name, ppt id, time, type ('mood', 'dot', 'vs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# start timer for duration of processing files\n",
    "start_file_sort = time.time()\n",
    "\n",
    "for i in all_files:\n",
    "\n",
    "    with open(i) as json_file:\n",
    "        data = json.load(json_file) # load JSON file\n",
    "        ppt_id = data['bbuid'] # set ppt_id\n",
    "        time_file = str(data['time']) # find time info from file\n",
    "        \n",
    "        # for mood files, save file name, ppt_id, time info, and file type (mood)\n",
    "        if 'm_d' in data['data']:\n",
    "            mood_files.append(i)\n",
    "            file_info.append([i,ppt_id,time_file,'mood'])\n",
    "\n",
    "        # sort DOT, VS, and other files; save file name, ppt_id, time info, and file type (mood)\n",
    "        elif 'data' in data['data']: \n",
    "            \n",
    "            if len(data['data']['data']) == 0:\n",
    "                other_files.append(i)\n",
    "                \n",
    "            elif data['data']['data'][0]['g_d']['g'] == 'SMI':\n",
    "                vs_files.append(i)\n",
    "                file_info.append([i,ppt_id,time_file,'vs'])\n",
    "\n",
    "            elif data['data']['data'][0]['g_d']['g'] == 'DOT':\n",
    "                dot_files.append(i)\n",
    "                file_info.append([i,ppt_id,time_file,'dot'])\n",
    "                \n",
    "            else:\n",
    "                other_files.append(i)\n",
    "\n",
    "        else:\n",
    "            other_files.append(i)\n",
    "\n",
    "# end timer for duration of processing files\n",
    "end_file_sort = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print description of file numbers\n",
    "\n",
    "# find time to sort files\n",
    "elapsed_time_sort = end_file_sort - start_file_sort\n",
    "print('Time to read and sort files in %H:%M:%S format: ',  time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time_sort)))\n",
    "\n",
    "# print info on numbers of files\n",
    "print('Number of mood files: ', len(mood_files))\n",
    "print('Number of dot files: ', len(dot_files))\n",
    "print('Number of vs files: ', len(vs_files))\n",
    "print('Number of other files: ', len(other_files))\n",
    "print('Total number of files: ', len(mood_files) + len(dot_files) + len(vs_files) + len(other_files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check file categorised as 'other' - no data was saved\n",
    "with open(other_files[0]) as json_file:\n",
    "    data = json.load(json_file)\n",
    "    print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create file_df dataframe; for each file, shows 'file_name', 'ppt_id', 'time_info', 'type' \n",
    "file_df = pd.DataFrame(file_info, columns = ['file_name', 'ppt_id', 'time_info', 'type'])\n",
    "file_df['time_cleaned'] =  pd.to_datetime(file_df['time_info'].astype(int)/1000, unit='s')\n",
    "file_df = file_df.sort_values(['file_name'], ascending=[True]) # order by file_name\n",
    "file_df['rolling_count_ppt'] = file_df.groupby(by='ppt_id').cumcount()+1\n",
    "file_df = file_df.reset_index(drop=True)\n",
    "file_df['time_day'] = file_df['time_cleaned'].dt.strftime('%Y-%m-%d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise dataframe\n",
    "file_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique ppt IDs from the 'ppt_id' column in file_df, without duplicates\n",
    "all_ppts = file_df['ppt_id'].drop_duplicates().to_list()\n",
    "print('Number of unique ppts: ', len(all_ppts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save DOT, VS and mood file names separately\n",
    "with open(\"../mood_files.txt\", \"w\") as outfile:\n",
    "    outfile.write(\"\\n\".join(str(item) for item in mood_files))\n",
    "\n",
    "with open(\"../vs_files.txt\", \"w\") as outfile:\n",
    "    outfile.write(\"\\n\".join(str(item) for item in vs_files))\n",
    "\n",
    "with open(\"../dot_files.txt\", \"w\") as outfile:\n",
    "    outfile.write(\"\\n\".join(str(item) for item in dot_files))\n",
    "\n",
    "# save list of all ppt IDs\n",
    "with open(\"../ppt_ids.txt\", \"w\") as outfile:\n",
    "    outfile.write(\"\\n\".join(str(item) for item in all_ppts))\n",
    " \n",
    "# save file_info dataframe as CSV\n",
    "file_df.to_csv(path_or_buf='../file_info.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Analyse dot-probe (DOT) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find names of all DOT files\n",
    "dot_txt = open(\"../dot_files.txt\",\"r\")\n",
    "dot_content = dot_txt.read()\n",
    "dot_files = dot_content.split(\"\\n\")\n",
    "dot_txt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataframe listing information about DOT files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_file_info = [] # to create df with cols: file name, ppt id, time, type\n",
    "\n",
    "start_dot_file_sort = time.time()\n",
    "\n",
    "get_game_info(dot_files, dot_file_info)\n",
    "\n",
    "end_dot_file_sort = time.time()\n",
    "elapsed_dot_file_sort_time = end_dot_file_sort - start_dot_file_sort\n",
    "\n",
    "print('Time to read and sort DOT files in %H:%M:%S format: ', time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_dot_file_sort_time)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dot_file_df as the dataframe\n",
    "dot_file_df = file_info_to_dataframe(dot_file_info, 'dot')\n",
    "\n",
    "# reorder columns in dataframe to group similar ones together\n",
    "dot_file_df = dot_file_df[['ppt_id', 'dot_file_name', 'file_type', 'time_info', 'time_cleaned', 'time_date', 'rolling_count_ppt']]\n",
    "\n",
    "# set time_info column as a numeric\n",
    "dot_file_df.time_info = pd.to_numeric(dot_file_df.time_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list total number of DOT files\n",
    "print('Total number of DOT files: ', len(dot_file_df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split participants by training type (active, sham), and remove any cases where participants did both types of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataframe by training file_type\n",
    "dot_active_training_df = dot_file_df[dot_file_df['file_type'] == \"active-training\"]\n",
    "dot_sham_training_df = dot_file_df[dot_file_df['file_type'] == \"sham-training\"]\n",
    "\n",
    "# find cases where patients did 1 file_type of training then the other - by whether they are both in dot_active_training_df & dot_sham_training_df \n",
    "dot_active_sham_df = pd.concat([dot_active_training_df[(dot_active_training_df[\"ppt_id\"].isin(dot_sham_training_df[\"ppt_id\"]))], dot_sham_training_df[(dot_sham_training_df[\"ppt_id\"].isin(dot_active_training_df[\"ppt_id\"]))]])\n",
    "dot_active_sham_df = dot_active_sham_df.sort_values(['dot_file_name'], ascending=[True])\n",
    "dot_active_sham_df = dot_active_sham_df.reset_index(drop=True)\n",
    "\n",
    "print('Number of patients with both dot active and sham training: ', dot_active_sham_df.ppt_id.nunique())\n",
    "print('Patient IDs with both DOT active and sham training: ', dot_active_sham_df.ppt_id.unique())\n",
    "\n",
    "print('Number patients with 1+ DOT active-training, before removing participants with both training types: ', dot_active_training_df.ppt_id.nunique())\n",
    "print('Number patients with 1+ DOT sham-training, before removing participants with both training types: ', dot_sham_training_df.ppt_id.nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# both ppts did several dot sham trainings before active training.\n",
    "# need to delete all files from and including the first time with active training\n",
    "\n",
    "# set time_info column as a numeric\n",
    "dot_file_df.time_info = pd.to_numeric(dot_file_df.time_info)\n",
    "\n",
    "# dot_file_df[dot_file_df['ppt_id'].str.match('AAlglYcdjt')] # inspect images\n",
    "# for ppt 'AAlglYcdjt', delete from this onwards: file_id: 'AAlglYcdjt-1496548054352-0', time: '1496548054352'\n",
    "dot_file_df_cleaned = dot_file_df.loc[~((dot_file_df['ppt_id'] == 'AAlglYcdjt') & (dot_file_df['time_info'] >= 1496548054352)),:]\n",
    "\n",
    "# dot_file_df[dot_file_df['ppt_id'].str.match('NfScLwnQSr')] # inspect images\n",
    "# for ppt 'NfScLwnQSr', delete from this onwards: file_id: 'NfScLwnQSr-1496686814167-0', time: '1496686814167'\n",
    "dot_file_df_cleaned = dot_file_df_cleaned.loc[~((dot_file_df_cleaned['ppt_id'] == 'NfScLwnQSr') & (dot_file_df_cleaned['time_info'] >= 1496686814167)),:]\n",
    "\n",
    "print('Number of rows and columns, before removing participants with both active and sham training: ', dot_file_df.shape)\n",
    "print('Number of rows and columns, after removing participants with both active and sham training: ', dot_file_df_cleaned.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe counts of files and unique participants with different DOT file types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataframe into active-training, sham-training, test, trial, and other(if exists) dataframes; find the number of files + ppts within each\n",
    "dot_active_training_df = dot_file_df_cleaned[dot_file_df_cleaned['file_type'] == \"active-training\"]\n",
    "dot_sham_training_df = dot_file_df_cleaned[dot_file_df_cleaned['file_type'] == \"sham-training\"]\n",
    "dot_test_files_df = dot_file_df_cleaned[dot_file_df_cleaned['file_type'] == \"test\"]\n",
    "dot_trial_files_df = dot_file_df_cleaned[dot_file_df_cleaned['file_type'] == \"trial\"]\n",
    "dot_other_df = dot_file_df_cleaned[dot_file_df_cleaned['file_type'] == \"other\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of unique ppts with any DOT responses: ', dot_file_df.ppt_id.nunique()) # check counts are as expected\n",
    "\n",
    "print('Number of unique patients with DOT tests: ', dot_test_files_df.ppt_id.nunique())\n",
    "print('Number of DOT test files: ', len(dot_test_files_df))\n",
    "\n",
    "print('Number of participants with DOT trial files: ', dot_trial_files_df.ppt_id.nunique())\n",
    "\n",
    "print('Number of non-training, test, or trial DOT files (if any): ', len(dot_other_df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataframe with all ppt IDs of participants with DOT files, and list their training type (active-training, sham-training, no-training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_ids_training_type_df = split_game_ids_by_training_type_in_dfs(dot_file_df_cleaned, dot_active_training_df, dot_sham_training_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe counts of DOT participants by training type\n",
    "print('Number of unique participants grouped by training type: \\n', \n",
    "      dot_ids_training_type_df.groupby('training_type').agg(['count']))\n",
    "\n",
    "dot_ids_training_type_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract reaction time, accuracy, and trial numbers for each DOT test file\n",
    "\n",
    "New fields to be added:\n",
    "* reaction_time (average RT for individual test session)\n",
    "* accuracy (average response accuracy for each file; max=1.0)\n",
    "* number_trials\n",
    "* rolling_test_count\n",
    "* total_test_count\n",
    "* ppt_training_type\n",
    "* days_elapsed_from_first_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dot_test_df which lists DOT test file information including responses\n",
    "dot_test_df = dot_test_files_df.drop(columns=['rolling_count_ppt'])\n",
    "dot_test_df.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_dot_test_read = time.time()\n",
    "\n",
    "for index, row in dot_test_df.iterrows():\n",
    "    with open(row['dot_file_name']) as json_file:\n",
    "        dot_test_data = json.load(json_file)\n",
    "\n",
    "        response_data = dot_test_data['data']['data'][0]['r_d']\n",
    "        \n",
    "        # work with cases that have information on  images presented to ppts:\n",
    "        if 'r_s' in response_data[0]: \n",
    "            len_trial_items = len(response_data)\n",
    "            num_trials = 0 # counter to find number of trials\n",
    "            rt_trials = []\n",
    "            acc_trials = []\n",
    "        \n",
    "            for i in range(len_trial_items):\n",
    "                if 'r_t' in response_data[i]:\n",
    "                    rt_score = response_data[i]['r_t']\n",
    "                    rt_trials.append(int(rt_score))\n",
    "                    accuracy_score = response_data[i]['res']\n",
    "                    acc_trials.append(is_correct(accuracy_score))\n",
    "                    num_trials += 1\n",
    "\n",
    "            dot_test_df.loc[index, 'mean_rt'] = np.mean(rt_trials)\n",
    "            dot_test_df.loc[index, 'mean_acc'] = np.mean(acc_trials)\n",
    "            dot_test_df.loc[index, 'num_trials'] = num_trials\n",
    "        \n",
    "        else: \n",
    "            \n",
    "            len_trial_items = len(response_data)\n",
    "            num_trials = 0\n",
    "            rt_trials = []\n",
    "            acc_trials = []\n",
    "        \n",
    "            for i in range(len_trial_items):\n",
    "                rt_score = response_data[i]['r_t']\n",
    "                rt_trials.append(int(rt_score))\n",
    "                accuracy_score = response_data[i]['res']\n",
    "                acc_trials.append(is_correct(accuracy_score))\n",
    "                num_trials += 1\n",
    "\n",
    "            dot_test_df.loc[index, 'mean_rt'] = np.mean(rt_trials)\n",
    "            dot_test_df.loc[index, 'mean_acc'] = np.mean(acc_trials)\n",
    "            dot_test_df.loc[index, 'num_trials'] = num_trials\n",
    "\n",
    "\n",
    "end_dot_test_read = time.time()\n",
    "elapsed_dot_test_read_time = end_dot_test_read - start_dot_test_read\n",
    "\n",
    "print('Time to read and calculate mean RTs and accuracies of DOT test files in %H:%M:%S format: ', time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_dot_test_read_time)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dot_test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove outliers from all test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for unusually fast reaction times\n",
    "dot_fast_rts = dot_test_df[dot_test_df['mean_rt'] < 50]\n",
    "print('Number of DOT test files with reaction times < 50ms: ', dot_fast_rts.ppt_id.count())\n",
    "\n",
    "# check for unusually slow reaction times\n",
    "dot_slow_rts = dot_test_df[dot_test_df['mean_rt'] > 5000]\n",
    "print('Number of DOT test files with reaction times > 5000ms: ', dot_slow_rts.ppt_id.count())\n",
    "\n",
    "# remove fast RTs\n",
    "dot_test_df_cleaned = dot_test_df.drop(dot_slow_rts.index)\n",
    "\n",
    "# check for tests where participants were answering below chance (accuracy < 0.5)\n",
    "dot_low_accuracy = dot_test_df_cleaned[dot_test_df_cleaned['mean_acc'] < 0.5]\n",
    "print('Number of DOT test files with accuracies < 0.5: ', dot_low_accuracy.ppt_id.count())\n",
    "\n",
    "# remove low accuracies\n",
    "dot_test_df_cleaned = dot_test_df_cleaned.drop(dot_low_accuracy.index)\n",
    "\n",
    "# reset index of dataframe\n",
    "dot_test_df_cleaned.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of DOT test files before removing outliers: ', len(dot_test_df))\n",
    "print('Number of DOT test files after removing outliers: ', len(dot_test_df_cleaned))\n",
    "print('Slowested RT in cleaned DOT test files, after removing outliers: ', np.round(dot_test_df_cleaned['mean_rt'].max(), decimals=2), \n",
    "      '\\n Fastest RT in cleaned DOT test files, after removing outliers: ', np.round(dot_test_df_cleaned['mean_rt'].min(), decimals=2))\n",
    "print('Lowest accuracy in cleaned DOT test files, after removing outliers: ', np.round(dot_test_df_cleaned['mean_acc'].min(), decimals=2),\n",
    "     '\\n Highest accuracy in cleaned DOT test files, after removing outliers: ', np.round(dot_test_df_cleaned['mean_acc'].max(), decimals=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each ppt, add rolling count of DOT test number to dot_test_df_cleaned\n",
    "dot_test_df_cleaned['rolling_test_count_by_ppt'] = dot_test_df_cleaned.groupby(by='ppt_id').cumcount()+1\n",
    "\n",
    "# For each ppt, add total number of test sessions completed\n",
    "dot_test_df_cleaned['total_test_count_by_ppt'] = dot_test_df_cleaned.groupby(by='ppt_id')['ppt_id'].transform('count')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add DOT training type of each ppt to DOT test df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add training type to the DOT test df (active, sham, none), by mapping from dot_ids_training_type_df\n",
    "dot_test_df_cleaned['training_type'] = dot_test_df_cleaned['ppt_id'].map(dot_ids_training_type_df.set_index('ppt_id')['training_type'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each participant, calculate the number of days between the first session and each subsequent session ('days_elapsed_from_first_test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add days_elapsed_from_first_test column to the DOT test df - for each ppt, this is the number of days between a session and the first session\n",
    "dot_test_df_cleaned['time_date'] = pd.to_datetime(dot_test_df_cleaned['time_date'])\n",
    "\n",
    "start_dot_test_days_elapsed_calc = time.time()\n",
    "\n",
    "dot_test_df_cleaned = dot_test_df_cleaned.assign(days_elapsed_from_first_test=dot_test_df_cleaned.groupby('ppt_id').time_date.apply(lambda x: x - x.iloc[0]))\n",
    "\n",
    "end_dot_test_days_elapsed_calc = time.time()\n",
    "\n",
    "elapsed_dot_test_days_elapsed_calc_time = end_dot_test_days_elapsed_calc - start_dot_test_days_elapsed_calc\n",
    "\n",
    "print('Time to calculate days elapsed from first DOT test files for each ppt in %H:%M:%S format: ', \n",
    "      time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_dot_test_days_elapsed_calc_time)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find numbers of patients with DOT test data after removing outliers, and split by training type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dot_test_ppts_analysis = dot_test_df_cleaned.ppt_id.nunique()\n",
    "print('Number of unique participants included in DOT test analysis, after removing outliers: ', num_dot_test_ppts_analysis)\n",
    "\n",
    "# check numbers are expected, and that no row doesn't have a training type:\n",
    "print('Number of unique patients with DOT test files, split by training: \\n', dot_test_df_cleaned[['ppt_id', 'training_type']].groupby('training_type').nunique('ppt_id'))\n",
    "print('Number of DOT test files, split by training performed by ppt: \\n', dot_test_df_cleaned[['ppt_id', 'training_type']].groupby('training_type').count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view structure of DOT test dataframe\n",
    "dot_test_df_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save csvs for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dot_file_df.to_csv(path_or_buf='../dot_file_info_training_not_cleaned.csv', index=False)\n",
    "# dot_file_df_cleaned.to_csv(path_or_buf='../dot_file_info_training_cleaned.csv', index=False)\n",
    "# dot_ids_training_type_df.to_csv(path_or_buf='../dot_ids_training_type_df.csv', index=False)\n",
    "# dot_test_df.to_csv(path_or_buf='../dot_test_responses_df_with_outliers.csv', index=False)\n",
    "# dot_test_df_cleaned.to_csv(path_or_buf='../dot_test_responses_df_without_outliers.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Analyse visual-search (VS) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find names of all VS files\n",
    "vs_txt = open(\"../vs_files.txt\",\"r\")\n",
    "vs_content = vs_txt.read()\n",
    "vs_files = vs_content.split(\"\\n\")\n",
    "vs_txt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataframe listing information about VS files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs_file_info = [] # to create df with cols: file name, ppt id, time, type\n",
    "\n",
    "start_vs_file_sort = time.time()\n",
    "\n",
    "get_game_info(vs_files, vs_file_info)\n",
    "\n",
    "end_vs_file_sort = time.time()\n",
    "elapsed_vs_file_sort_time = end_vs_file_sort - start_vs_file_sort\n",
    "\n",
    "print('Time to read and sort VS files in %H:%M:%S format: ', time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_vs_file_sort_time)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create vs_file_df as the dataframe\n",
    "vs_file_df = file_info_to_dataframe(vs_file_info, 'vs')\n",
    "\n",
    "# reorder columns in dataframe to group similar ones together\n",
    "vs_file_df = vs_file_df[['ppt_id', 'vs_file_name', 'file_type', 'time_info', 'time_cleaned', 'time_date', 'rolling_count_ppt']]\n",
    "\n",
    "# set time_info column as a numeric\n",
    "vs_file_df.time_info = pd.to_numeric(vs_file_df.time_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list total number of VS files\n",
    "print('Total number of VS files: ', len(vs_file_df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split participants by training type (active, sham), and remove any cases where participants did both types of training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataframe by training file_type\n",
    "vs_active_training_df = vs_file_df[vs_file_df['file_type'] == \"active-training\"]\n",
    "vs_sham_training_df = vs_file_df[vs_file_df['file_type'] == \"sham-training\"]\n",
    "\n",
    "# find cases where patients did 1 file_type of training then the other - by whether they are both in vs_active_training_df & vs_sham_training_df \n",
    "vs_active_sham_df = pd.concat([vs_active_training_df[(vs_active_training_df[\"ppt_id\"].isin(vs_sham_training_df[\"ppt_id\"]))], vs_sham_training_df[(vs_sham_training_df[\"ppt_id\"].isin(vs_active_training_df[\"ppt_id\"]))]])\n",
    "vs_active_sham_df = vs_active_sham_df.sort_values(['vs_file_name'], ascending=[True])\n",
    "vs_active_sham_df = vs_active_sham_df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe outputs\n",
    "print('Number of patients with both VS active and sham training: ', vs_active_sham_df.ppt_id.nunique())\n",
    "print('Patient IDs with both VS active and sham training: ', vs_active_sham_df.ppt_id.unique())\n",
    "\n",
    "print('Number patients with 1+ VS active-training, before removing any participants with both training types: ', \n",
    "      vs_active_training_df.ppt_id.nunique())\n",
    "print('Number patients with 1+ VS sham-training, before removing any participants with both training types: ', \n",
    "      vs_sham_training_df.ppt_id.nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # inspect images of patient with active and sham training\n",
    "# vs_file_df[vs_file_df['ppt_id'].str.match('gnUnXlzcJP')]\n",
    "print('Participant did several VS active trainings before sham training. \\n \\\n",
    "Remove all files from + including the first time with sham training.')\n",
    "\n",
    "# for ppt 'gnUnXlzcJP', delete from this time onwards: 1501311001449\n",
    "vs_file_df_cleaned = vs_file_df.loc[~((vs_file_df['ppt_id'] == 'gnUnXlzcJP') & (vs_file_df['time_info'] >= 1501311001449)),:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe outputs after removing these cases\n",
    "print('Number of rows and columns, before removing participants with both active and sham training: ', \n",
    "      vs_file_df.shape)\n",
    "print('Number of rows and columns, after removing participants with both active and sham training: ', \n",
    "      vs_file_df_cleaned.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe counts of files and unique participants with different VS file types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataframe into active-training, sham-training, test, trial, and other(if exists) dataframes; find the number of files + ppts within each\n",
    "vs_active_training_df = vs_file_df_cleaned[vs_file_df_cleaned['file_type'] == \"active-training\"]\n",
    "vs_sham_training_df = vs_file_df_cleaned[vs_file_df_cleaned['file_type'] == \"sham-training\"]\n",
    "vs_test_files_df = vs_file_df_cleaned[vs_file_df_cleaned['file_type'] == \"test\"]\n",
    "vs_trial_files_df = vs_file_df_cleaned[vs_file_df_cleaned['file_type'] == \"trial\"]\n",
    "vs_other_df = vs_file_df_cleaned[vs_file_df_cleaned['file_type'] == \"other\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of unique ppts with any VS responses: ', vs_file_df_cleaned.ppt_id.nunique()) # check counts are as expected\n",
    "\n",
    "print('Number of unique patients with VS tests: ', vs_test_files_df.ppt_id.nunique())\n",
    "print('Number of VS test files: ', len(vs_test_files_df))\n",
    "\n",
    "print('Number of participants with VS trial files: ', vs_trial_files_df.ppt_id.nunique())\n",
    "\n",
    "print('Number of non-training, test, or trial VS files (if any): ', len(vs_other_df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataframe with all ppt IDs of participants with VS files, and list their training type (active-training, sham-training, no-training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs_ids_training_type_df = split_game_ids_by_training_type_in_dfs(vs_file_df_cleaned, vs_active_training_df, vs_sham_training_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe counts of VS participants by training type\n",
    "print('Number of unique participants grouped by training type: \\n', \n",
    "      vs_ids_training_type_df.groupby('training_type').agg(['count']))\n",
    "\n",
    "vs_ids_training_type_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract reaction time, accuracy, and trial numbers for each VS test file\n",
    "\n",
    "New fields to be added:\n",
    "* reaction_time (average RT for individual test session)\n",
    "* accuracy (average response accuracy for each file; max=1.0)\n",
    "* number_trials\n",
    "* rolling_test_count\n",
    "* total_test_count\n",
    "* ppt_training_type\n",
    "* days_elapsed_from_first_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create vs_test_df which lists VS test file information including responses\n",
    "vs_test_df = vs_test_files_df.drop(columns=['rolling_count_ppt'])\n",
    "vs_test_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_vs_test_read = time.time()\n",
    "\n",
    "for index, row in vs_test_df.iterrows():\n",
    "    with open(row['vs_file_name']) as json_file:\n",
    "        vs_test_data = json.load(json_file)\n",
    "\n",
    "        # access first section of vs test data\n",
    "        response_data_1 = vs_test_data['data']['data'][0]['r_d']\n",
    "        # access second section of vs test data\n",
    "        response_data_2 = vs_test_data['data']['data'][1]['r_d']\n",
    "        \n",
    "        # work with cases that have information on  images presented to ppts:\n",
    "        if 'r_s' in response_data_1[0]: \n",
    "\n",
    "            # get reaction time and accuracy from first section of vs test data\n",
    "            # get number of items\n",
    "            len_trial_items_1 = len(response_data_1)\n",
    "            # counter to find number of trials\n",
    "            num_trials_1 = 0\n",
    "            # lists to store reaction times and accuracies\n",
    "            rt_trials_1 = []\n",
    "            acc_trials_1 = []\n",
    "            # extract the rt and acc scores\n",
    "            for i in range(len_trial_items_1):\n",
    "                if 'r_t' in response_data_1[i]:\n",
    "                    rt_score = response_data_1[i]['r_t']\n",
    "                    rt_trials_1.append(int(rt_score))\n",
    "                    accuracy_score = response_data_1[i]['res']\n",
    "                    acc_trials_1.append(is_correct(accuracy_score))\n",
    "                    num_trials_1 += 1\n",
    "\n",
    "\n",
    "            # get number of items in second section of vs test data\n",
    "            len_trial_items_2 = len(response_data_2)\n",
    "            # counter to find number of trials in first section of vs test data\n",
    "            num_trials_2 = 0 \n",
    "            # lists to store reaction times and accuracies\n",
    "            rt_trials_2 = []\n",
    "            acc_trials_2 = []\n",
    "            # extract the rt and acc scores\n",
    "            for i in range(len_trial_items_2):\n",
    "                if 'r_t' in response_data_2[i]:\n",
    "                    rt_score = response_data_2[i]['r_t']\n",
    "                    rt_trials_2.append(int(rt_score))\n",
    "                    accuracy_score = response_data_2[i]['res']\n",
    "                    acc_trials_2.append(is_correct(accuracy_score))\n",
    "                    num_trials_2 += 1\n",
    "\n",
    "            # find combined reaction time, accuracy, and total number of trials across whole test session\n",
    "            rt_trials_all = rt_trials_1 + rt_trials_2\n",
    "            acc_trials_all = acc_trials_1 + acc_trials_2\n",
    "            num_trials_all = num_trials_1 + num_trials_2\n",
    "\n",
    "            # add mean reaction time, accuracy, and number of trials for the VS test file to the test dataframe\n",
    "            vs_test_df.loc[index, 'mean_rt'] = np.mean(rt_trials_all)\n",
    "            vs_test_df.loc[index, 'mean_acc'] = np.mean(acc_trials_all)\n",
    "            vs_test_df.loc[index, 'num_trials'] = num_trials_all\n",
    "        \n",
    "        else: \n",
    "\n",
    "            # get reaction time and accuracy from first section of vs test data\n",
    "            # get number of items\n",
    "            len_trial_items_1 = len(response_data_1)\n",
    "            # counter to find number of trials\n",
    "            num_trials_1 = 0\n",
    "            # lists to store reaction times and accuracies\n",
    "            rt_trials_1 = []\n",
    "            acc_trials_1 = []\n",
    "            # extract the rt and acc scores\n",
    "            for i in range(len_trial_items_1):\n",
    "                rt_score = response_data_1[i]['r_t']\n",
    "                rt_trials_1.append(int(rt_score))\n",
    "                accuracy_score = response_data_1[i]['res']\n",
    "                acc_trials_1.append(is_correct(accuracy_score))\n",
    "                num_trials_1 += 1\n",
    "\n",
    "\n",
    "            # get number of items in second section of vs test data\n",
    "            len_trial_items_2 = len(response_data_2)\n",
    "            # counter to find number of trials in first section of vs test data\n",
    "            num_trials_2 = 0 \n",
    "            # lists to store reaction times and accuracies\n",
    "            rt_trials_2 = []\n",
    "            acc_trials_2 = []\n",
    "            # extract the rt and acc scores\n",
    "            for i in range(len_trial_items_2):\n",
    "                rt_score = response_data_2[i]['r_t']\n",
    "                rt_trials_2.append(int(rt_score))\n",
    "                accuracy_score = response_data_2[i]['res']\n",
    "                acc_trials_2.append(is_correct(accuracy_score))\n",
    "                num_trials_2 += 1\n",
    "\n",
    "            # find combined reaction time, accuracy, and total number of trials across whole test session\n",
    "            rt_trials_all = rt_trials_1 + rt_trials_2\n",
    "            acc_trials_all = acc_trials_1 + acc_trials_2\n",
    "            num_trials_all = num_trials_1 + num_trials_2\n",
    "\n",
    "            # add mean reaction time, accuracy, and number of trials for the VS test file to the test dataframe\n",
    "            vs_test_df.loc[index, 'mean_rt'] = np.mean(rt_trials_all)\n",
    "            vs_test_df.loc[index, 'mean_acc'] = np.mean(acc_trials_all)\n",
    "            vs_test_df.loc[index, 'num_trials'] = num_trials_all\n",
    "\n",
    "end_vs_test_read = time.time()\n",
    "elapsed_vs_test_read_time = end_vs_test_read - start_vs_test_read\n",
    "\n",
    "print('Time to read and calculate mean RTs and accuracies of VS test files in %H:%M:%S format: ', time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_vs_test_read_time)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vs_test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove outliers from all test files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for unusually fast reaction times\n",
    "vs_fast_rts = vs_test_df[vs_test_df['mean_rt'] < 50]\n",
    "print('Number of VS test files with reaction times < 50ms: ', vs_fast_rts.ppt_id.count())\n",
    "\n",
    "# remove fast RTs\n",
    "vs_test_df_cleaned = vs_test_df.drop(vs_fast_rts.index)\n",
    "\n",
    "# check for unusually slow reaction times\n",
    "vs_slow_rts = vs_test_df_cleaned[vs_test_df_cleaned['mean_rt'] > 7750]\n",
    "print('Number of VS test files with reaction times > 7750, after removing fast RTs: ', vs_slow_rts.ppt_id.count())\n",
    "\n",
    "# remove fast RTs\n",
    "vs_test_df_cleaned = vs_test_df_cleaned.drop(vs_slow_rts.index)\n",
    "\n",
    "# check for tests where participants were answering below chance (accuracy < 0.5)\n",
    "vs_low_accuracy = vs_test_df_cleaned[vs_test_df_cleaned['mean_acc'] < 0.5]\n",
    "print('Number of VS test files with accuracies < 0.5, after removing fast & slow RTs: ', vs_low_accuracy.ppt_id.count())\n",
    "\n",
    "# remove low accuracies\n",
    "vs_test_df_cleaned = vs_test_df_cleaned.drop(vs_low_accuracy.index)\n",
    "\n",
    "# reset index of dataframe\n",
    "vs_test_df_cleaned.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of VS test files before removing outliers: ', len(vs_test_df))\n",
    "print('Number of VS test files after removing outliers: ', len(vs_test_df_cleaned))\n",
    "print('Slowested RT in cleaned VS test files, after removing outliers: ', np.round(vs_test_df_cleaned['mean_rt'].max(), decimals=2), \n",
    "      '\\n Fastest RT in cleaned VS test files, after removing outliers: ', np.round(vs_test_df_cleaned['mean_rt'].min(), decimals=2))\n",
    "print('Lowest accuracy in cleaned VS test files, after removing outliers: ', np.round(vs_test_df_cleaned['mean_acc'].min(), decimals=2),\n",
    "     '\\n Highest accuracy in cleaned VS test files, after removing outliers: ', np.round(vs_test_df_cleaned['mean_acc'].max(), decimals=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add additional fields to VS test df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each ppt, add rolling count of VS test number to vs_test_df_cleaned\n",
    "vs_test_df_cleaned['rolling_test_count_by_ppt'] = vs_test_df_cleaned.groupby(by='ppt_id').cumcount()+1\n",
    "\n",
    "# For each ppt, add total number of test sessions completed\n",
    "vs_test_df_cleaned['total_test_count_by_ppt'] = vs_test_df_cleaned.groupby(by='ppt_id')['ppt_id'].transform('count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add training type to the VS test df (active, sham, none), by mapping from vs_ids_training_type_df\n",
    "vs_test_df_cleaned['training_type'] = vs_test_df_cleaned['ppt_id'].map(vs_ids_training_type_df.set_index('ppt_id')['training_type'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add days_elapsed_from_first_test column to the VS test df - for each ppt, this is the number of days between a session and the first session\n",
    "vs_test_df_cleaned['time_date'] = pd.to_datetime(vs_test_df_cleaned['time_date'])\n",
    "\n",
    "start_vs_test_days_elapsed_calc = time.time()\n",
    "\n",
    "vs_test_df_cleaned = vs_test_df_cleaned.assign(days_elapsed_from_first_test=vs_test_df_cleaned.groupby('ppt_id').time_date.apply(lambda x: x - x.iloc[0]))\n",
    "\n",
    "end_vs_test_days_elapsed_calc = time.time()\n",
    "\n",
    "elapsed_vs_test_days_elapsed_calc_time = end_vs_test_days_elapsed_calc - start_vs_test_days_elapsed_calc\n",
    "\n",
    "print('Time to calculate days elapsed from first VS test files for each ppt in %H:%M:%S format: ', \n",
    "      time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_vs_test_days_elapsed_calc_time)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find numbers of patients with VS test data after removing outliers, and split by training type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_vs_test_ppts_analysis = vs_test_df_cleaned.ppt_id.nunique()\n",
    "print('Number of unique participants included in VS test analysis, after removing outliers: ', num_vs_test_ppts_analysis)\n",
    "\n",
    "# check numbers are expected, and that no row doesn't have a training type:\n",
    "print('Number of unique patients with VS test files, split by training: \\n', vs_test_df_cleaned[['ppt_id', 'training_type']].groupby('training_type').nunique('ppt_id'))\n",
    "print('Number of VS test files, split by training performed by ppt: \\n', vs_test_df_cleaned[['ppt_id', 'training_type']].groupby('training_type').count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view structure of VS test dataframe\n",
    "vs_test_df_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save csvs for future use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vs_file_df.to_csv(path_or_buf='../vs_file_info_training_not_cleaned.csv', index=False)\n",
    "# vs_file_df_cleaned.to_csv(path_or_buf='../vs_file_info_training_cleaned.csv', index=False)\n",
    "# vs_ids_training_type_df.to_csv(path_or_buf='../vs_ids_training_type_df.csv', index=False)\n",
    "# vs_test_df.to_csv(path_or_buf='../vs_test_responses_df_with_outliers.csv', index=False)\n",
    "# vs_test_df_cleaned.to_csv(path_or_buf='../vs_test_responses_df_without_outliers.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Process mood (PANAS/HAS) responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mood_txt = open(\"../mood_files.txt\",\"r\")\n",
    "mood_content = mood_txt.read()\n",
    "mood_files = mood_content.split(\"\\n\")\n",
    "mood_txt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create vars for PANAS questionaire responses and for Happy/Anxious/Sad\n",
    "\n",
    "- mood dataframe: lists file_name, ppt_id, time, and type for each file ('panas', 'has')\n",
    "- PANAS var: struct w ppt_id, time and data for PANAS files only\n",
    "-  HAS var: struct w ppt_id, time and data for HAS files only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create lists to store file names + info\n",
    "panas_files = []\n",
    "has_files = []\n",
    "other_mood_files = []\n",
    "mood_ppts = []\n",
    "mood_file_info = [] # to create df with cols: file name, ppt id, time, type ('panas', 'has')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_mood_file_sort = time.time()\n",
    "\n",
    "for i in mood_files:\n",
    "\n",
    "    with open(i) as json_file:\n",
    "        mood_data = json.load(json_file)\n",
    "        mood_ppt_id = mood_data['bbuid']\n",
    "        mood_time_file = str(mood_data['time'])\n",
    "\n",
    "        if len(mood_data['data']['m_d']) == 20: \n",
    "            panas_files.append(i)\n",
    "            mood_file_info.append([mood_ppt_id,i,mood_time_file,'panas'])\n",
    "\n",
    "        elif len(mood_data['data']['m_d']) == 3:\n",
    "            has_files.append(i)\n",
    "            mood_file_info.append([mood_ppt_id,i,mood_time_file,'has'])\n",
    "\n",
    "        else:\n",
    "            other_mood_files.append(i)\n",
    "\n",
    "end_mood_file_sort = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elapsed_mood_file_sort = end_mood_file_sort - start_mood_file_sort\n",
    "\n",
    "print('Time to read and sort mood files in %H:%M:%S format: ', \n",
    "      time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_mood_file_sort)))\n",
    "print('Number of mood files: ', len(mood_files))\n",
    "print('Number of panas files: ', len(panas_files))\n",
    "print('Number of has files: ', len(has_files))\n",
    "print('Number of other files: ', len(other_mood_files))\n",
    "print('Total number of mood files: ', len(has_files) + len(panas_files) + len(other_mood_files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mood_file_df as the dataframe\n",
    "mood_file_df = file_info_to_dataframe(mood_file_info, 'mood')\n",
    "\n",
    "# reorder columns in dataframe to group similar ones together\n",
    "mood_file_df = mood_file_df[['ppt_id', 'mood_file_name', 'file_type', 'time_info', 'time_cleaned', 'time_date', 'rolling_count_ppt']]\n",
    "\n",
    "# set time_info column as a numeric\n",
    "mood_file_df.time_info = pd.to_numeric(mood_file_df.time_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique ppt IDs from the 'ppt_id' column in file_df, without duplicates\n",
    "mood_ppts = mood_file_df['ppt_id'].drop_duplicates().to_list()\n",
    "print('Number of unique ppts with mood responses: ', len(mood_ppts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove files from ppts who did more than 1 type of training\n",
    "\n",
    "# set time_info column as a numeric\n",
    "mood_file_df.time_info = pd.to_numeric(mood_file_df.time_info)\n",
    "\n",
    "# use same cut-off times for participants as in the DOT/VS cleaning steps above\n",
    "mood_file_df_cleaned = mood_file_df.loc[~((mood_file_df['ppt_id'] == 'AAlglYcdjt') & (mood_file_df['time_info'] >= 1496548054352)),:]\n",
    "mood_file_df_cleaned = mood_file_df_cleaned.loc[~((mood_file_df_cleaned['ppt_id'] == 'gnUnXlzcJP') & (mood_file_df_cleaned['time_info'] >= 1501311001449)),:]\n",
    "mood_file_df_cleaned = mood_file_df_cleaned.loc[~((mood_file_df_cleaned['ppt_id'] == 'NfScLwnQSr') & (mood_file_df_cleaned['time_info'] >= 1496686814167)),:]\n",
    "\n",
    "print('Number of rows, before removing participants with both active and sham training on any task: ', len(mood_file_df))\n",
    "print('Number of rows, after removing participants with both active and sham training on any task: ', len(mood_file_df_cleaned))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # visualise first few rows of dataframe\n",
    "# mood_file_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a PANAS-specific dataframe\n",
    "panas_rows_df = mood_file_df_cleaned[mood_file_df_cleaned['file_type'] == \"panas\"] # select only PANAS file types\n",
    "\n",
    "panas_rows_df = panas_rows_df.sort_values(['mood_file_name'], ascending=[True]) # order by file_name\n",
    "\n",
    "panas_rows_df.reset_index(drop=True, inplace=True) # reset index\n",
    "\n",
    "panas_rows_df.drop(columns=['rolling_count_ppt'], inplace=True) # drop column as not useful for this dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of unique patients with PANAS responses: ', panas_rows_df['ppt_id'].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a HAS-specific dataframe\n",
    "has_rows_df = mood_file_df_cleaned[mood_file_df_cleaned['file_type'] == \"has\"]\n",
    "print('Number of unique patients with HAS responses: ', has_rows_df['ppt_id'].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sets of unique ppt ids for both PANAS files and HAS files\n",
    "unique_panas_ppt_ids = set(panas_rows_df['ppt_id'].unique())\n",
    "unique_has_ppt_ids = set(has_rows_df['ppt_id'].unique())\n",
    "\n",
    "# find ppts with both PANAS and HAS\n",
    "mood_commonalities = unique_panas_ppt_ids.intersection(unique_has_ppt_ids)\n",
    "print('Number of unique ppts with both panas and has responses: ', len(mood_commonalities))\n",
    "\n",
    "# find ppts with HAS and not PANAS\n",
    "has_not_panas_ids = unique_has_ppt_ids - mood_commonalities\n",
    "print('Number of unique ppts with has and not panas responses: ', len(has_not_panas_ids))\n",
    "\n",
    "# find ppts with PANAS and not HAS\n",
    "panas_not_has_ids = unique_panas_ppt_ids - mood_commonalities\n",
    "print('Number of unique ppts with panas and not has responses: ', len(panas_not_has_ids))\n",
    "\n",
    "print('Number of unique ppts with any mood responses: ', len(mood_commonalities) + len(has_not_panas_ids) + len(panas_not_has_ids))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add columns to PANAS-specific dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add days_elapsed column: days between each PANAS report and the ppt's first PANAS report\n",
    "\n",
    "panas_rows_df['time_date'] = pd.to_datetime(panas_rows_df['time_date'])\n",
    "\n",
    "start_panas_days_elapsed_calc = time.time()\n",
    "\n",
    "panas_rows_df = panas_rows_df.assign(days_elapsed_from_first_report=panas_rows_df.groupby('ppt_id').time_date.apply(lambda x: x - x.iloc[0]))\n",
    "\n",
    "end_panas_days_elapsed_calc = time.time()\n",
    "\n",
    "elapsed_panas_days_elapsed_calc_time = end_panas_days_elapsed_calc - start_panas_days_elapsed_calc\n",
    "\n",
    "print('Time to calculate days elapsed from first PANAS report files for each ppt in %H:%M:%S format: ', \n",
    "      time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_panas_days_elapsed_calc_time)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each ppt, add total number of PANAS reports completed\n",
    "panas_rows_df['total_panas_count_by_ppt'] = panas_rows_df.groupby(by='ppt_id')['ppt_id'].transform('count')\n",
    "\n",
    "# For each ppt, add rolling count of PANAS files\n",
    "panas_rows_df['panas_rolling_count_ppt'] = panas_rows_df.groupby(by='ppt_id').cumcount()+1 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract responses from panas and has json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new fields to panas_rows_df: each of the 20 questions + responses, rolling_count_test_no, total_panas_tests, training_type, days_elapsed\n",
    "panas_q_a = []\n",
    "\n",
    "for i in panas_files:\n",
    "    with open(i) as json_file:\n",
    "        data = json.load(json_file)\n",
    "        \n",
    "        for question in range(20):\n",
    "            panas_q_a.append([i, data['data']['m_d'][question]['q'], data['data']['m_d'][question]['a']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create panas_q_a_df listing the questions and responses for each file\n",
    "panas_q_a_df = pd.DataFrame(panas_q_a, columns = ['mood_file_name', 'question', 'answer'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot dataframe to change from long to wide format\n",
    "pivot_panas_q_a_df = panas_q_a_df.pivot(index='mood_file_name', columns='question', values='answer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panas_rows_df = pd.merge(panas_rows_df, pivot_panas_q_a_df, on='mood_file_name')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn responses into numbers: \n",
    "\n",
    "* 1 = Not At All, \n",
    "* 2 = A Little, \n",
    "* 3 = Moderately, \n",
    "* 4 = Quite a Bit, \n",
    "* 5 = Extremely\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set scale\n",
    "answer_mapping = {'Not At All': 1, 'A Little': 2, 'Moderately': 3, 'Quite A Bit': 4, 'Extremely': 5}\n",
    "# replace text values with numeric ones\n",
    "panas_rows_values_df = panas_rows_df.applymap(lambda a: answer_mapping.get(a) if a in answer_mapping else a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add compound PA and NA, and overall mood scores for each mood file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panas_rows_values_df['PA'] = (panas_rows_values_df['Interested'] + panas_rows_values_df['Excited'] + panas_rows_values_df['Strong']\n",
    "                             + panas_rows_values_df['Enthusiastic'] + panas_rows_values_df['Proud'] + panas_rows_values_df['Alert']\n",
    "                             + panas_rows_values_df['Inspired'] + panas_rows_values_df['Determined'] + panas_rows_values_df['Attentive']\n",
    "                             + panas_rows_values_df['Active'])\n",
    "\n",
    "panas_rows_values_df['NA'] = (panas_rows_values_df['Distressed'] + panas_rows_values_df['Upset'] + panas_rows_values_df['Guilty']\n",
    "                             + panas_rows_values_df['Scared'] + panas_rows_values_df['Hostile'] + panas_rows_values_df['Irritable']\n",
    "                             + panas_rows_values_df['Ashamed'] + panas_rows_values_df['Nervous'] + panas_rows_values_df['Jittery']\n",
    "                             + panas_rows_values_df['Afraid'])\n",
    "\n",
    "panas_rows_values_df['mood'] = panas_rows_values_df['PA'] - panas_rows_values_df['NA']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # visualise PANAS dataframe with quantities that can be used for analyses\n",
    "# panas_rows_values_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add DOT and VS training type to the PANAS dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in DOT and VS ppt IDs by training type CSVs\n",
    "dot_ids_training_type_df = pd.read_csv('../dot_ids_training_type_df.csv')\n",
    "vs_ids_training_type_df = pd.read_csv('../vs_ids_training_type_df.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panas_rows_values_by_training_df = add_game_training_type_to_mood_dfs(panas_rows_values_df, dot_ids_training_type_df, 'dot')\n",
    "panas_rows_values_by_training_df = add_game_training_type_to_mood_dfs(panas_rows_values_by_training_df, vs_ids_training_type_df, 'vs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for patients with both VS and DOT training\n",
    "panas_training_overlap = panas_rows_values_by_training_df.loc[((panas_rows_values_by_training_df['dot_training_type'].str.contains('active|sham', regex=True)) \n",
    "                                      & (panas_rows_values_by_training_df['vs_training_type'].str.contains('active|sham', regex=True))),:]\n",
    "\n",
    "print('Number of ppts with both VS and DOT training: ', panas_training_overlap.ppt_id.nunique())\n",
    "# print('ppt_ids of ppts with both VS and DOT training: ', panas_training_overlap.ppt_id.unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect ppt's DOT and VS data to find which training type was conducted first, and the cutoff for excluding data\n",
    "\n",
    "# read in csvs\n",
    "dot_file_info_training_cleaned = pd.read_csv('../dot_file_info_training_cleaned.csv')\n",
    "vs_file_info_training_cleaned = pd.read_csv('../vs_file_info_training_cleaned.csv')\n",
    "\n",
    "# inspect all rows for this ppt\n",
    "# print(dot_file_info_training_cleaned[dot_file_info_training_cleaned['ppt_id'].str.match('PXpDwlCoZL')]) # inspect images\n",
    "# print(vs_file_info_training_cleaned[vs_file_info_training_cleaned['ppt_id'].str.match('PXpDwlCoZL')]) # inspect images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ppt 'PXpDwlCoZL', delete from this time onwards: '1516531705886', as ppt training for anlternative task\n",
    "panas_rows_values_by_training_df_cleaned = panas_rows_values_by_training_df.loc[~((panas_rows_values_by_training_df['ppt_id'] == 'PXpDwlCoZL') & (panas_rows_values_by_training_df['time_info'] >= 1516531705886)),:]\n",
    "\n",
    "panas_rows_values_by_training_df_cleaned.reset_index(drop=True, inplace=True) # reset index\n",
    "\n",
    "# replace the vs_training_type column for this patient with 'no-training', as they did not do VS training in data considered\n",
    "panas_rows_values_by_training_df_cleaned.loc[(panas_rows_values_by_training_df_cleaned['ppt_id'] == 'PXpDwlCoZL'), 'vs_training_type'] = 'no-training'\n",
    "\n",
    "print('Number of rows, before removing participants with both active and sham training on any task: ', len(panas_rows_values_by_training_df))\n",
    "print('Number of rows, after removing participants with both active and sham training on any task: ', len(panas_rows_values_by_training_df_cleaned))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_panas_dot_active = panas_rows_values_by_training_df_cleaned[panas_rows_values_by_training_df_cleaned['dot_training_type'] == \"active-training\"].ppt_id.nunique()\n",
    "num_panas_dot_sham = panas_rows_values_by_training_df_cleaned[panas_rows_values_by_training_df_cleaned['dot_training_type'] == \"sham-training\"].ppt_id.nunique()\n",
    "\n",
    "num_panas_vs_active = panas_rows_values_by_training_df_cleaned[panas_rows_values_by_training_df_cleaned['vs_training_type'] == \"active-training\"].ppt_id.nunique()\n",
    "num_panas_vs_sham = panas_rows_values_by_training_df_cleaned[panas_rows_values_by_training_df_cleaned['vs_training_type'] == \"sham-training\"].ppt_id.nunique()\n",
    "\n",
    "num_any_panas = panas_rows_values_by_training_df_cleaned.ppt_id.nunique()\n",
    "num_panas_no_training = num_any_panas - num_panas_dot_active - num_panas_dot_sham - num_panas_vs_active - num_panas_vs_sham\n",
    "\n",
    "print('# unique ppts with PANAS reports who did 1+ DOT active training session: ', num_panas_dot_active)\n",
    "print('# unique ppts with PANAS reports who did 1+ DOT sham training session: ', num_panas_dot_sham)\n",
    "print('# unique ppts with PANAS reports who did 1+ VS active training session: ', num_panas_vs_active)\n",
    "print('# unique ppts with PANAS reports who did 1+ VS sham training session: ', num_panas_vs_sham)\n",
    "print('# unique ppts with PANAS reports without any training sessions: ', num_panas_no_training)\n",
    "print('# unique ppts with PANAS reports, regardless of training: ', num_any_panas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_panas_dot_active_reports = panas_rows_values_by_training_df_cleaned[panas_rows_values_by_training_df_cleaned['dot_training_type'] == \"active-training\"].mood_file_name.count()\n",
    "num_panas_dot_sham_reports = panas_rows_values_by_training_df_cleaned[panas_rows_values_by_training_df_cleaned['dot_training_type'] == \"sham-training\"].mood_file_name.count()\n",
    "\n",
    "num_panas_vs_active_reports = panas_rows_values_by_training_df_cleaned[panas_rows_values_by_training_df_cleaned['vs_training_type'] == \"active-training\"].mood_file_name.count()\n",
    "num_panas_vs_sham_reports = panas_rows_values_by_training_df_cleaned[panas_rows_values_by_training_df_cleaned['vs_training_type'] == \"sham-training\"].mood_file_name.count()\n",
    "\n",
    "num_any_panas_reports = panas_rows_values_by_training_df_cleaned.mood_file_name.count()\n",
    "num_panas_no_training_reports = num_any_panas_reports - num_panas_dot_active_reports - num_panas_dot_sham_reports - num_panas_vs_active_reports - num_panas_vs_sham_reports\n",
    "\n",
    "print('# PANAS reports for ppts who did 1+ DOT active training session: ', num_panas_dot_active_reports)\n",
    "print('# PANAS reports for ppts who did 1+ DOT sham training session: ', num_panas_dot_sham_reports)\n",
    "print('# PANAS reports for ppts who did 1+ VS active training session: ', num_panas_vs_active_reports)\n",
    "print('# PANAS reports for ppts who did 1+ VS sham training session: ', num_panas_vs_sham_reports)\n",
    "print('# PANAS reports for ppts without any training sessions: ', num_panas_no_training_reports)\n",
    "print('# PANAS reports, regardless of training: ', num_any_panas_reports)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panas_rows_values_by_training_df_cleaned = mood_overall_training_category(panas_rows_values_by_training_df_cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualise outputs of dataframe, prior to analysis\n",
    "panas_rows_values_by_training_df_cleaned.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save mood outputs as CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# panas_rows_values_df.to_csv(path_or_buf='../panas_rows_values_df_not_cleaned.csv', index=False)\n",
    "# panas_rows_values_by_training_df_cleaned.to_csv(path_or_buf='../panas_rows_values_by_training_df_cleaned.csv', index=False)\n",
    "\n",
    "# mood_file_df.to_csv(path_or_buf='../mood_file_df_not_cleaned.csv', index=False)\n",
    "# mood_file_df_cleaned.to_csv(path_or_buf='../mood_file_df_cleaned.csv', index=False)\n",
    "\n",
    "with open(\"../has_files.txt\", \"w\") as outfile:\n",
    "    outfile.write(\"\\n\".join(str(item) for item in has_files))\n",
    "\n",
    "with open(\"../panas_files.txt\", \"w\") as outfile:\n",
    "    outfile.write(\"\\n\".join(str(item) for item in panas_files))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare PANAS files for analysis and create plots for mood scores by training type and time\n",
    "\n",
    "Create dataframes for analysis with 2 PANAS reports and 6 PANAS reports, separately\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read whole dataframe, with columns of interest\n",
    "panas_df = pd.read_csv('~/bias_mod_analysis/panas_rows_values_by_training_df_cleaned.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select rows where (a) each ppt has at least 2 PANAS reports, and (b) only the 1st & 2nd PANAS reports are selected \n",
    "two_panas_df = panas_df.loc[(panas_df['total_panas_count_by_ppt'] >= 2) & (panas_df['panas_rolling_count_ppt'] <= 2), :]\n",
    "two_panas_df = two_panas_df[['ppt_id', 'mood', 'panas_rolling_count_ppt', 'overall_training_type']]\n",
    "two_panas_df.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view first few rows of df\n",
    "two_panas_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape from long to wide format for analysis\n",
    "two_panas_wide_df = two_panas_df.pivot_table(index=['ppt_id', 'overall_training_type'], \n",
    "                                        columns='panas_rolling_count_ppt', values='mood').reset_index()\n",
    "# rename time column\n",
    "two_panas_wide_df.rename(columns={1: \"report_1\", 2: \"report_2\"}, inplace=True)\n",
    "\n",
    "# remove axis name\n",
    "two_panas_wide_df = two_panas_wide_df.rename_axis(None, axis=1)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view first few rows of df\n",
    "two_panas_wide_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select rows where (a) each ppt has at least 6 PANAS reports, and (b) only the 1st & 6th PANAS reports are selected \n",
    "six_panas_df = panas_df.loc[(panas_df['total_panas_count_by_ppt'] >= 6) & (panas_df['panas_rolling_count_ppt'] <= 6), :]\n",
    "six_panas_df = six_panas_df[['ppt_id', 'mood', 'panas_rolling_count_ppt', 'overall_training_type']]\n",
    "six_panas_df.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape from long to wide format for analysis\n",
    "six_panas_wide_df = six_panas_df.pivot_table(index=['ppt_id', 'overall_training_type'], \n",
    "                                        columns='panas_rolling_count_ppt', values='mood').reset_index()\n",
    "# rename time column\n",
    "six_panas_wide_df.rename(columns={1: \"report_1\", 2: \"report_2\", 3: \"report_3\", 4: \"report_4\", 5: \"report_5\", 6: \"report_6\"}, inplace=True)\n",
    "\n",
    "# remove axis name\n",
    "six_panas_wide_df = six_panas_wide_df.rename_axis(None, axis=1)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as csvs\n",
    "two_panas_wide_df.to_csv(path_or_buf='two_panas_wide_df.csv', index=False)\n",
    "six_panas_wide_df.to_csv(path_or_buf='six_panas_wide_df.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}